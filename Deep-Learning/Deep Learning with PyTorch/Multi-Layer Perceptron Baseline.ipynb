{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb1afb3-59d3-4bc4-949a-67dba6d2df01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (fc_input): Linear(in_features=5, out_features=32, bias=True)\n",
      "  (fc_hidden1): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (fc_hidden2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc_hidden3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc_out): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▋                                                         | 274/1000 [00:56<02:22,  5.09it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# Load datasets\n",
    "dataset = pd.read_csv('./practice_data.csv')\n",
    "\n",
    "\n",
    "# Split target and variables\n",
    "X = dataset.drop(['DATETIME', 'QGEN'], axis=1).to_numpy()\n",
    "Y = dataset['QGEN'].to_numpy().reshape(-1,1)\n",
    "\n",
    "\n",
    "# Split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, shuffle=False, random_state=777)\n",
    "\n",
    "\n",
    "\n",
    "# Normalization\n",
    "def normalization(numpy_array):\n",
    "    df = pd.DataFrame(numpy_array).copy()\n",
    "    \n",
    "    # Column index is number of variables\n",
    "    for column_index in range(len(df.columns)):\n",
    "        df[column_index] = (df[column_index] - df[column_index].min()) / (df[column_index].max() - df[column_index].min())\n",
    "    \n",
    "    # Convert dataframe to numpy\n",
    "    normalized_df = df.to_numpy()\n",
    "    \n",
    "    return normalized_df\n",
    "\n",
    "x_train_norm = normalization(x_train)\n",
    "y_train_norm = normalization(y_train)\n",
    "\n",
    "x_test_norm = normalization(x_test)\n",
    "y_test_norm = normalization(y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Convert numpy to tensor\n",
    "class TensorData(Dataset): # torch의 Dataset 클래스 상속\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.y_data = torch.FloatTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "# # Set fixed random number seed\n",
    "# torch.manual_seed(777)\n",
    "    \n",
    "    \n",
    "# Iteration 객체 반환하는 데이터로더\n",
    "trainsets = TensorData(x_train_norm, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainsets, batch_size=64, shuffle=True)\n",
    "\n",
    "testsets = TensorData(x_test_norm, y_test)\n",
    "testloader = torch.utils.data.DataLoader(testsets, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Define a Artifical Neural Network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"모델 연산 정의\"\"\"\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc_input = nn.Linear(5, 32, bias=True, device=None)        # input_node=5, output_node=32\n",
    "        self.fc_hidden1 = nn.Linear(32, 64, bias=True, device=None)     # input_node=32, output_node=64\n",
    "        self.fc_hidden2 = nn.Linear(64, 64, bias=True, device=None)     # input_node=64, output_node=64\n",
    "        self.fc_hidden3 = nn.Linear(64, 32, bias=True, device=None)     # input_node=64, output_node=32\n",
    "        self.fc_out = nn.Linear(32, 1, bias=True, device=None)          # input_node=32, output_node=1\n",
    "        self.dropout = nn.Dropout(0.2)                                  # 일정 비율로 랜덤하게 Node 제거\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"모델 연산 순서 정의\"\"\"\n",
    "        x = F.relu(self.fc_input(x))                                    # Linear 계산 후 활성화 함수 적용\n",
    "        x = F.relu(self.fc_hidden1(x))\n",
    "        x = F.relu(self.fc_hidden2(x))\n",
    "#         x = self.dropout(F.relu(self.fc_hidden2(x)))\n",
    "        x = F.relu(self.fc_hidden3(x))\n",
    "        out = F.relu(self.fc_out(x))\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# Create ANN Instance\n",
    "model = NeuralNetwork()\n",
    "print(model)\n",
    "\n",
    "\n",
    "# Define a Loss function and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "# Training\n",
    "loss_epoch = []\n",
    "for i in tqdm(range(1000)): # 1000 epoch \n",
    "    \n",
    "    batch_loss = 0.0 # 한 에폭이 돌 때 배치마다 loss가 나온다. 즉 한번 학습할 때 배치마다 loss가 나오니 MSE를 구하기 위해서 초기화\n",
    "    \n",
    "    for idx, batch in enumerate(trainloader):\n",
    "\n",
    "        inputs, labels = batch                 # 배치 데이터\n",
    "        \n",
    "        optimizer.zero_grad()                  # 옵티마이저 초기화 (역전파 전에 그래디언트 초기화)\n",
    "        outputs = model(inputs)                # 모델에 입력값을 넣어 예측값 산출\n",
    "        loss = loss_func(outputs, labels)      # compute loss\n",
    "        loss.backward()                        # compute gradients (dloss/dx)\n",
    "        optimizer.step()                       # 역전파를 진행하고 가중치를 업데이트\n",
    "        \n",
    "        batch_loss += loss.item()\n",
    "        \n",
    "    loss_epoch.append(batch_loss / trainloader.dataset.__len__())\n",
    "    \n",
    "plt.plot(loss_epoch)\n",
    "plt.title('Loss(MSE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "\n",
    "print(loss_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpp",
   "language": "python",
   "name": "vpp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
